from __future__ import print_function, division
import pprint

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn

import torchvision
from torchvision import datasets, models, transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, models, transforms

import time
import os

from PIL import Image

import numpy as np
import pandas as pd


cudnn.benchmark = True


def collate_fn(batch):
    return [
        torch.stack([x[0] for x in batch]),
        torch.tensor(np.array([x[1] for x in batch])),
    ]


# data_dir = "/mnt/g/onlinelessons/deep learning/dataset/train_full_malware/ByteToImage/on_board/"
data_dir = "/mnt/project/dataset/on_board/"


class image_custom_dataset(Dataset):
    """Face Landmarks dataset."""

    def __init__(self, csv_file, transform=None):
        """
        Arguments:
            csv_file (string): Path to the csv file with labels.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """

        self.image_csv = pd.read_csv(csv_file)
        self.transform = transforms.Compose(
            [
                transforms.Resize(256),
                transforms.ToTensor(),
            ]
        )

    def __len__(self):
        return len(self.image_csv)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        image_name = self.image_csv.iloc[idx, 1]
        image = Image.open(image_name)

        label = self.image_csv.iloc[idx, 3:12]
        label = np.array(label, dtype=np.float16)

        if self.transform:
            image = self.transform(image)

        if image.shape[0] == 1:
            image = torch.cat((image, image, image), dim=0)

        image = transforms.Compose(
            [
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                )
            ]
        )(image)

        return_tuple = tuple([image, label])

        return return_tuple


# test_dir = "/mnt/g/onlinelessons/deep learning/dataset/train_full_malware/ByteToImage/on_board/test"
test_dir = "/mnt/project/dataset/on_board/test"

image_datasets = {
    x.split("_")[0]: image_custom_dataset(os.path.join(data_dir, x))
    for x in ["test_data_encoded - Copy.csv"]
}
batch_size = 4

dataloaders = {
    "test": torch.utils.data.DataLoader(
        image_datasets["test"],
        batch_size=batch_size,
        shuffle=True,
        num_workers=4,
        collate_fn=collate_fn,
    )
}

dataset_sizes = {x: len(image_datasets[x]) for x in ["test"]}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(dataset_sizes["test"])
len(dataloaders["test"])

image_datasets = {
    x.split("_")[0]: image_custom_dataset(os.path.join(data_dir, x))
    for x in ["test_data_encoded - Copy.csv"]
}
batch_size = 4

dataloaders = {
    "test": torch.utils.data.DataLoader(
        image_datasets["test"],
        batch_size=batch_size,
        shuffle=True,
        num_workers=4,
        collate_fn=collate_fn,
    )
}

dataset_sizes = {x: len(image_datasets[x]) for x in ["test"]}

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(dataset_sizes["test"])
len(dataloaders["test"])

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(torch.cuda.is_available())


def pipeline_module(model_list, confidence_factor=0.8):
    print(f"Confidence factor: {confidence_factor}")

    was_training = []

    for models in model_list:
        was_training.append(models.training)
        models.eval()

    model = model_list[0]

    pred_in_each_step = [0, 0, 0, 0]

    total_run_time = 0

    total = 0

    model = model.to(device)

    with torch.no_grad():
        since = time.time()
        for i, (inputs, _) in enumerate(dataloaders["test"]):
            inputs = inputs.to(device)

            outputs = model(inputs)
            preds = outputs

            _, predicted_labels = torch.max(preds, dim=1)
            predicted_labels = predicted_labels.clone().detach()

            for j, batch in enumerate(preds):
                if float(batch[int(predicted_labels[j])]) < confidence_factor:
                    stronger_model = model_list[1]
                    stronger_model = stronger_model.to(device)
                    strong_inputs = inputs[j]
                    strong_inputs = strong_inputs.unsqueeze(0)

                    strong_outputs = stronger_model(strong_inputs)
                    strong_preds = strong_outputs
                    _, strong_labels = torch.tensor(torch.max(strong_preds, dim=1))

                    if float(strong_preds[0][int(strong_labels)]) < confidence_factor:
                        stronger_model = model_list[2]
                        stronger_model = stronger_model.to(device)

                        strong_outputs = stronger_model(strong_inputs)
                        strong_preds = strong_outputs
                        _, strong_labels = torch.tensor(torch.max(strong_preds, dim=1))
                        predicted_labels[j] = strong_labels
                        pred_in_each_step[2] += 1

                    else:
                        predicted_labels[j] = strong_labels
                        pred_in_each_step[1] += 1

                else:
                    pred_in_each_step[0] += 1

            total = total + inputs.size(0)

        time_elapsed = time.time() - since

        for i, train_mode in enumerate(was_training):
            model_list[i].train(mode=train_mode)

        for k, steps_power in enumerate(pred_in_each_step):
            print(
                "\033[36m"
                + f"{pred_in_each_step[k]} predicted in {k}th layer"
                + "\033[0m"
            )

        print(f"datas handled by each layer = {pred_in_each_step}")

        print("\033[33m" + f"run-time(overall) = {time_elapsed}" + "\033[0m")

        print(
            "\033[34m"
            + f"run-time(per input in second) = {time_elapsed / total}"
            + "\033[0m"
        )

    return {
        "run-time": time_elapsed,
    }


import torch.nn.functional as F

class FireModule(nn.Module):
    def __init__(self, in_channels, s1x1, e1x1, e3x3):
        super(FireModule, self).__init__()
        self.squeeze = nn.Conv2d(in_channels, s1x1, kernel_size=1)
        self.expand_1x1 = nn.Conv2d(s1x1, e1x1, kernel_size=1)
        self.expand_3x3 = nn.Conv2d(s1x1, e3x3, kernel_size=3, padding=1)

    def forward(self, x):
        x = F.relu(self.squeeze(x))
        return torch.cat(
            [F.relu(self.expand_1x1(x)), F.relu(self.expand_3x3(x))], dim=1
        )


class SqueezeNet(nn.Module):
    def __init__(self, num_classes=9):
        super(SqueezeNet, self).__init__()
        self.num_classes = 9
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=11, stride=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),
            FireModule(96, 64, 128, 128),
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Conv2d(256, self.num_classes, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x.view(-1, self.num_classes)


os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

model1 = SqueezeNet()
model1 = model1.to(device)


class Linear_layers_fc(torch.nn.Module):
    def __init__(self):
        super(Linear_layers_fc, self).__init__()

        self.linear2 = torch.nn.Linear(1280, 9)

        self.dropout2 = nn.Dropout(p=0.2)

        self.softmax = torch.nn.Softmax(dim=1)

    def forward(self, x):
        x = self.dropout2(x)
        x = self.linear2(x)

        x = self.softmax(x)
        return x


linear_layers_mobilenet = Linear_layers_fc()

print("The model:")
print(linear_layers_mobilenet)

model3 = torch.hub.load("pytorch/vision:v0.10.0", "mobilenet_v2", pretrained=True)

num_classes = 9
model3.classifier = linear_layers_mobilenet

model3 = model3.to(device)

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

class_num = 9

model4 = models.resnet18(pretrained=True)
num_ftrs = model4.fc.in_features
model4.fc = nn.Linear(num_ftrs, class_num)

model4 = model4.to(device)
model4


model_1_dir = "./squeeznet_combined_best_256_better.pth"
model_3_dir = "./mobilenet_v2_9_finetuned_combined_256.pth"
model_4_dir = "./resnet18_finetuned-smote-256_new_better2.pth"


model1.load_state_dict(torch.load(model_1_dir))
model1 = nn.Sequential(model1, nn.Softmax())
model3.load_state_dict(torch.load(model_3_dir))
model4.load_state_dict(torch.load(model_4_dir))

models_list = []
models_list.append(model1)
models_list.append(model3)
models_list.append(model4)


conf_list = [0.97]
for i in range(1):
    results = pipeline_module(models_list, confidence_factor=conf_list[i])
